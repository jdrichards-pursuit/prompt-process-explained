# AI Language Model Quiz

<img src="./assets/question-mark.webp" alt="Quiz" width="300">

Let's test your knowledge of how AI language models work.

### 1. What happens first when you send a prompt to the OpenAI API?
<details>
  <summary>View Solution</summary>
  **Answer**: C) The prompt is sent to OpenAIâ€™s servers.
</details>

---

### 2. What are tokens in the context of AI language models?
<details>
  <summary>View Solution</summary>
  **Answer**: B) Smaller pieces of the input like whole words, parts of words, or punctuation.
</details>

---

### 3. What are embeddings in AI language models?
<details>
  <summary>View Solution</summary>
  **Answer**: A) Lists of numbers that represent the meaning of tokens.
</details>

---

### 4. What is the function of the attention mechanism in transformers?
<details>
  <summary>View Solution</summary>
  **Answer**: A) To focus on the most important tokens in the input.
</details>

---

### 5. What are the two main parts of the transformer layers?
<details>
  <summary>View Solution</summary>
  **Answer**: B) Self-attention and feed-forward layers.
</details>

---

### 6. What happens during inference in an AI language model?
<details>
  <summary>View Solution</summary>
  **Answer**: A) The model makes predictions one token at a time.
</details>

---

### 7. How does the model decide what token comes next during inference?
<details>
  <summary>View Solution</summary>
  **Answer**: A) By calculating probabilities of the next most likely token.
</details>

---

### 8. After the model has generated all tokens, what does it do?
<details>
  <summary>View Solution</summary>
  **Answer**: B) It sends the response back to the user as human-readable text.
</details>

---

### 9. What is the purpose of the feed-forward layers in the transformer architecture?
<details>
  <summary>View Solution</summary>
  **Answer**: B) To process the information and make predictions.
</details>

---

### 10. What is a key takeaway about tokens?
<details>
  <summary>View Solution</summary>
  **Answer**: B) Tokens can be parts of words, symbols, or punctuation.
</details>
