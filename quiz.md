# AI Language Model Quiz

<img src="./assets/question-mark.webp" alt="Quiz" width="500">

Let's test your knowledge of how AI language models work.

### 1. What happens first when you send a prompt to the OpenAI API?

- A) The model breaks the prompt into tokens.
- B) The model runs through transformer layers.
- C) The prompt is sent to OpenAI’s servers.
- D) The model makes predictions.

<details>
  <summary>View Solution</summary>
  **Answer**: C) The prompt is sent to OpenAI’s servers.
</details>

---

### 2. What are tokens in the context of AI language models?

- A) Small images used by the model.
- B) Smaller pieces of the input like whole words, parts of words, or punctuation.
- C) Large sections of text.
- D) Final predictions made by the model.

<details>
  <summary>View Solution</summary>
  **Answer**: B) Smaller pieces of the input like whole words, parts of words, or punctuation.
</details>

---

### 3. What are embeddings in AI language models?

- A) Lists of numbers that represent the meaning of tokens.
- B) Final responses given by the model.
- C) Predictions made by the model.
- D) Parts of the model’s attention mechanism.

<details>
  <summary>View Solution</summary>
  **Answer**: A) Lists of numbers that represent the meaning of tokens.
</details>

---

### 4. What is the function of the attention mechanism in transformers?

- A) To focus on the most important tokens in the input.
- B) To make predictions for the model’s response.
- C) To convert tokens into numbers.
- D) To break down the prompt into tokens.

<details>
  <summary>View Solution</summary>
  **Answer**: A) To focus on the most important tokens in the input.
</details>

---

### 5. What are the two main parts of the transformer layers?

- A) Tokenization and inference.
- B) Self-attention and feed-forward layers.
- C) Embeddings and responses.
- D) Prediction and attention layers.

<details>
  <summary>View Solution</summary>
  **Answer**: B) Self-attention and feed-forward layers.
</details>

---

### 6. What happens during inference in an AI language model?

- A) The model makes predictions one token at a time.
- B) The model breaks the input into smaller tokens.
- C) The model focuses on important words.
- D) The model converts tokens into embeddings.

<details>
  <summary>View Solution</summary>
  **Answer**: A) The model makes predictions one token at a time.
</details>

---

### 7. How does the model decide what token comes next during inference?

- A) By calculating probabilities of the next most likely token.
- B) By focusing only on the input’s punctuation.
- C) By using final predictions from the start.
- D) By choosing tokens randomly.

<details>
  <summary>View Solution</summary>
  **Answer**: A) By calculating probabilities of the next most likely token.
</details>

---

### 8. After the model has generated all tokens, what does it do?

- A) It converts the tokens into numbers.
- B) It sends the response back to the user as human-readable text.
- C) It breaks the response into smaller pieces.
- D) It runs the input through transformer layers again.

<details>
  <summary>View Solution</summary>
  **Answer**: B) It sends the response back to the user as human-readable text.
</details>

---

### 9. What is the purpose of the feed-forward layers in the transformer architecture?

- A) To apply the attention mechanism.
- B) To process the information and make predictions.
- C) To break down the prompt into tokens.
- D) To convert the input into embeddings.

<details>
  <summary>View Solution</summary>
  **Answer**: B) To process the information and make predictions.
</details>

---

### 10. What is a key takeaway about tokens?

- A) Tokens are the same as full words.
- B) Tokens can be parts of words, symbols, or punctuation.
- C) Tokens are not used in language models.
- D) Tokens are only used during inference.

<details>
  <summary>View Solution</summary>
  **Answer**: B) Tokens can be parts of words, symbols, or punctuation.
</details>
